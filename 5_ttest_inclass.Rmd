--
title: "Introduction to R for Biostatistics 5"
output: html_document
---

```{r global_options, include=FALSE}
library(plyr)
library(dplyr)
library(ggplot2)
library(Rmisc)
library(MASS)  
```
#In-class worksheet 5

**29 Feb to 4 Mar, 2016**

In this worksheet you will learn how to compute confidence intervals and use t-tests in R.

## Confidence intervals

Please review briefly sample and population.

> Your answer here.

In many cases, we are interested in not only estimating a mean of a population from a finite sample, but also quantifying our uncertainty about it.

We can do this by computing a confidence interval. The 95%-confidence interval encompasses - if the experiment was to be repeated many times - the true mean in 95% of the cases. Note that for any single instantiation of the experiment you can never be sure. 

For the confindence interval, we need again the quantity called standard error of the mean. As you have seen in the simulations before, this measures the precision with which the mean can be estimated from the data. Typically, if a 95%-CI does not overlap with a reference value, we say that the value is significantly different from that value. 

### Confidence interval for the mean

The confidence interval for the mean is given by: $m \pm t_{\alpha/2,n-1} SE$

The $t_{\alpha/2,n-1}$ is the $100 \cdot (1-\alpha/2)$-percentile of a t-distribution. You can estimate this using the quantile function for the t-distribution *qt*. The t-distribution has a free parameter called degrees of freedom, and we set it to $n-1$. 

Consider an example, in which you want to estimate the height of student population. By hand, compute the mean and 95%-confidence interval.

```{r}
height.response = na.omit(survey$Height)

# your code here

```

Please write a short sentence describing your result.

> Your answer here.

### Confidence interval for a proportion

Often you also need to compute a confidence for a proportion. There are different ways how to do this. A simple approximation is to use the following formula:

$$ \bar{p} \pm z_{\alpha/2} \sqrt{\frac{\bar{p}(1-\bar{p})}{n}} $$

Here, $z_{\alpha/2}$ is the $100 \cdot (1-\alpha/2)$-percentile of a normal distribution and can be obtain using *qnorm*. 

For the same survey data, estimate the proportion of male students with 95%-confidence interval. For this you will need that for a bernoulli variable (a binary outcome variable), the standard deviation is $\sqrt{p(1-p)}$.


```{r}
                # load the MASS package 
student.sex = na.omit(survey$Sex)


# your code here

```

Write a conclusion sentence.

> Your answer here.

As we said, this is an approximation. For values around 0.5, this approximation is good, but there are more complicated formulas for values close to 0 and 1.

## Tests

In the lecture, you learned about statistical null hypothesis testing. This is a very standardized procedures that is used extensively all over the biomedical literature. It works as follows:

1. **You define a null hypothesis.** Typically it states that there is no effect.
2. **Calculate a test statistic.** This measures a property of the data related to what you want to test. Typically larger (absolute) values mean that the data is in stronger disagreement with the null hypothesis.
3. Determine the **distribution of the test statistic** assuming your null-hypothesis is true.
4. From this distribution, **compute the p-value**, the probability that the test statistic will be as or more extreme than the observed value of the test statistic, according to this distribution.
5. **Compare the p-value** to the desired $\alpha$-level. If it is smaller, reject the null hypothesis.


### Chi-square test for two independent samples

The qui-square test is useful for comparing the proportion of success of a dichotomous variable to a reference level or between two or more groups. Let's consider the case where we compare proportions between two groups. For example, we would like to test whether boys and girls prefer different TV shows. 80 boys and 130 girls were asked if they prefer *The Lone Ranger* or *Sesame Street*. We want to know if the proportion of boys preferring *The Lone Ranger* is the same as for girls and so on. You can find the tabulated results in the next code section. Write down the null hypothesis and the alternative hypothesis in your own words .

> Your answer here.

As a test statistic we use:

$$\chi^2 = \sum_{i=(boys,girls)}{}\sum_{j=(lr,ss)}{2} \frac{(o_{ij}-e_{ij})^2}{e_{ij}}$$

Here, $o_{ij}$ are the observed values for each cell and $e_{ij}=frac{n_r n_c}{n}$ is the expected value for a given tv show and sex.   

If the null hypothesis is true, the test statistic follows a so-called chi2-distribution with 1 degree of freedom, because we have two categories. Using this information, we can compute the p-value. 

Implement the missing lines of code. The *filter* function may come in handy. 

```{r}
preferences <- read.csv("D:/lab/teaching/statistics2016/R_for_biostatistics/tvshows.csv")

# find out what the function count does!
tab <- count(preferences,sex,tvshow)

# extract the cell counts, i.e. the observed n for each combination of sex and tv show


# compute row n's, i.e. how many boys/girls


# compute column n's, i.e. how many prefer the shows irrespective of their sex


# compute total n


# compute expected counts


# compute chi2


# compute p-value

# p
```

Formulate a sentence summarizing this result.

> Your answer here.

Let's compare our manual result to the result of the corresponding R function (*chisq.test*; set the *correct* option to FALSE):

```{r}
# your code here
```

If you implemented everything correctly, this will look reassuring.

### Two sample t-test 

The t-test is widely used for comparing the means of two independent samples. It assumes that the data is normally distributed. In practise, the test is quite robust against violations of this assumption, but many journals require you justifying its use nonetheless. If the data is normally distributed, the test has more power (i.e. lower type II error rate) than its non-parametric alternatives.

We will work on the blood pressure example from the lecture. That is, we sample 20 patients and assign them to two groups randomly. The two groups are treated with two different hypertensive drugs for lowering blood pressure. As we have learned before, explore the data and create a suitable plot for comparing the two groups.  

```{r}
data <- read.csv("D:/lab/teaching/statistics2016/R_for_biostatistics/bloodpressur.csv",sep=";")
data$Group = factor(data$Group)


# your code here

```

Formulate the null and the alternative hypothesis.

> Your answer here.

A central assumption of the t-test is that the data is normally distributed. Make a qq-plot to check this assumption.

```{r}
# your code here
```

In practice, the test is fairly robust against violations of this assumption.

The test statistic is 
$$ t = \frac{m_1 - m_2}{s_{pooled}} \sqrt{\frac{n_1 n_2}{n_1 + n_2}}, $$
where $s_{pooled} = \sqrt{\frac{1}{n_1+n_2-2} [(n_1-1)s_1^2 + (n_2-1)s_2^2]}$ is the pooled standard deviation. If the sample sizes are not too different, this is roughly equal to the average standard deviation. 

Compute the value of the test statistic for the two samples.

```{r}

# your code here

```

We next need to compare the value of the test statistic against the distribution of the test statistic, assuming the null-hypothesis is true. In this case, this is the t-distribution. The t-distribution has a parameter called degrees of freedome - it is equal to $n_1+n_2-2$. You want to do a two-sided test. Briefly explain what that means.

> You answer here.

For computing the p-value you need to find the probability of observing a value of t as or more extreme as the absolute value of the observed one under the null hypothesis. Use the function *qt* to compute the p-value. Make sure you think of both sides of the distribution. 

```{r}

# your code here
```


Of course, you can also use the build in R function *t.test* to obtain the p-value. Use the help to find out how to use it.

```{r}
# your code here
```

Did you calculations give the same values? If yes, summarize the outcome of the testing procedure in one sentence.

> Your answer here.


### Non-parametric alternative to the t-test

The Wilcoxon rank sum test or Mann-Whitney-U-test is an alternative to the t-test, that is most commonly used if the data does not meet the assumptions of the t-test, i.e. if it is not normally distributed. We checked above that the data in this case is normally distributed. Find out how to use *wilcox.test* and observe how the p-value changes.


```{r}
# your code here
```

What do you observe? Do you have an idea why that happens?

> You answer here.




